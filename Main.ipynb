{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "from collections import Counter\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the html strips\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text().lower()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['review']=df['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(df['review'])\n",
    "all_text = ' '.join(reviews)\n",
    "all_text2 = ''.join([c for c in all_text if c not in punctuation])\n",
    "words = all_text2.split()\n",
    "vocab = list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_words = Counter(words)\n",
    "total_words = len(words)\n",
    "sorted_words = count_words.most_common(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222701"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
    "len(vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_split = []\n",
    "for r in reviews:\n",
    "    sen = []\n",
    "    for c in r:\n",
    "        if c not in punctuation:\n",
    "            sen.append(c)\n",
    "    reviews_split.append(\"\".join(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one of the other reviewers has mentioned that after watching just 1 oz episode youll be hooked they are right as this is exactly what happened with methe first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the wordit is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far awayi would say the main appeal of the show is due to the fact that it goes where other shows wouldnt dare forget pretty pictures painted for mainstream audiences forget charm forget romanceoz doesnt mess around the first episode i ever saw struck me as so nasty it was surreal i couldnt say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards wholl be sold out for a nickel inmates wholl kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewingthats if you can get in touch with your darker side',\n",
       " 'a wonderful little production the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done',\n",
       " 'i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air conditioned theater and watching a lighthearted comedy the plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer while some may be disappointed when they realize this is not match point 2 risk addiction i thought it was proof that woody allen is still fully in control of the style many of us have grown to lovethis was the most id laughed at one of woodys comedies in years dare i say a decade while ive never been impressed with scarlet johanson in this she managed to tone down her sexy image and jumped right into a average but spirited young womanthis may not be the crown jewel of his career but it was wittier than devil wears prada and more interesting than superman a great comedy to go see with friends',\n",
       " 'basically theres a family where a little boy jake thinks theres a zombie in his closet  his parents are fighting all the timethis movie is slower than a soap opera and suddenly jake decides to become rambo and kill the zombieok first of all when youre going to make a film you must decide if its a thriller or a drama as a drama the movie is watchable parents are divorcing  arguing like in real life and then we have jake with his closet which totally ruins all the film i expected to see a boogeyman similar movie and instead i watched a drama with some meaningless thriller spots3 out of 10 just for the well playing parents  descent dialogs as for the shots with jake just ignore them',\n",
       " 'petter matteis love in the time of money is a visually stunning film to watch mr mattei offers us a vivid portrait about human relations this is a movie that seems to be telling us what money power and success do to people in the different situations we encounter this being a variation on the arthur schnitzlers play about the same theme the director transfers the action to the present time new york where all these different characters meet and connect each one is connected in one way or another to the next person but no one seems to know the previous point of contact stylishly the film has a sophisticated luxurious look we are taken to see how these people live and the world they live in their own habitatthe only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits a big city is not exactly the best place in which human relations find sincere fulfillment as one discerns is the case with most of the people we encounterthe acting is good under mr matteis direction steve buscemi rosario dawson carol kane michael imperioli adrian grenier and the rest of the talented cast make these characters come alivewe wish mr mattei good luck and await anxiously for his next work']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_split[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27, 4, 1, 77, 1929, 42, 1058, 11, 100, 144, 39, 507, 3339, 393, 457, 25, 3146, 33, 22, 204, 13, 10, 6, 593, 46, 582, 14, 7542, 87, 145, 11, 3220, 68, 41, 3339, 12, 28, 5509, 2, 14964, 131, 4, 584, 60, 282, 7, 204, 35, 1, 661, 137, 1723, 68, 10, 6, 20, 3, 117, 15, 1, 8156, 5707, 38, 11583, 10, 117, 2479, 54, 5959, 14, 5619, 5, 1457, 381, 38, 584, 28, 6, 3383, 7, 1, 351, 339, 4, 1, 61031, 6, 461, 3339, 13, 11, 6, 1, 11410, 344, 5, 1, 15572, 6799, 2538, 1056, 61032, 8, 2604, 1365, 19, 24632, 533, 32, 4683, 2496, 4, 1, 1197, 112, 30, 1, 7005, 24, 2951, 12693, 2, 405, 61033, 37, 17027, 6, 20, 317, 19, 1, 5027, 3693, 533, 6, 340, 5, 83365, 8283, 39961, 14965, 5116, 7734, 2439, 2, 17028, 61034, 328, 9083, 7324, 13108, 2, 8534, 33912, 22, 108, 224, 21280, 56, 124, 1, 267, 1291, 4, 1, 117, 6, 663, 5, 1, 185, 11, 8, 260, 112, 77, 254, 547, 2964, 818, 177, 1262, 4291, 15, 2472, 1092, 818, 1400, 818, 83366, 146, 969, 180, 1, 87, 393, 9, 119, 200, 3220, 68, 13, 37, 1569, 8, 12, 2188, 9, 395, 124, 9, 12, 1540, 15, 8, 17, 13, 9, 275, 49, 9, 1454, 3, 1239, 15, 3339, 2, 181, 10060, 5, 1, 317, 2070, 4, 2082, 584, 20, 39, 584, 17, 7802, 7006, 4908, 13805, 25, 2921, 43, 15, 3, 31674, 6897, 13805, 489, 19, 611, 2, 74, 238, 14, 8, 72, 9718, 746, 808, 6897, 105, 655, 76, 1197, 19977, 663, 5, 62, 550, 4, 925, 1979, 38, 1197, 554, 144, 3339, 21, 193, 409, 3727, 14, 46, 6, 3238, 83367, 44, 21, 67, 74, 7, 1200, 14, 121, 3987, 501], [3, 382, 113, 357, 1, 1352, 2986, 6, 50, 17894, 50, 83368, 1620, 2, 389, 3, 13109, 2, 516, 26839, 277, 4, 1874, 5, 1, 417, 406, 1, 148, 22, 544, 72, 2251, 496, 4643, 20, 59, 42, 181, 30, 1, 83369, 17, 26, 42, 30, 1, 2202, 183, 3288, 98, 21, 67, 352, 63, 1, 13559, 788, 10061, 31, 1, 1780, 5, 1663, 7492, 6617, 20, 59, 6, 8, 72, 266, 1, 144, 17, 8, 6, 3, 39962, 426, 2, 2350, 406, 3, 4315, 357, 41, 27, 4, 1, 78, 3168, 4, 212, 2, 23, 118, 1, 1874, 61, 258, 340, 14, 1, 113, 176, 1, 1063, 4, 1, 2965, 60, 239, 69, 339, 1, 2124, 1018, 3124, 1233, 1141, 91, 4979, 8, 285, 19, 250, 1781, 2, 250, 4531, 566, 14, 1, 131, 3566, 19390, 2, 28248, 2, 1, 705, 566, 4, 62, 1088, 14, 83370, 61035, 28249, 166, 2245, 22, 1889, 72, 222], [9, 191, 10, 12, 3, 382, 96, 5, 1105, 58, 19, 3, 98, 898, 1465, 2459, 1182, 7, 1, 942, 16267, 756, 2, 144, 3, 3974, 212, 1, 114, 6, 3999, 17, 1, 403, 6, 1843, 2, 1, 99, 22, 1461, 52, 1, 72, 6529, 6569, 1533, 493, 135, 45, 193, 25, 689, 51, 33, 922, 10, 6, 20, 1044, 219, 297, 2952, 5117, 9, 191, 8, 12, 3003, 11, 2927, 2035, 6, 126, 1367, 7, 1143, 4, 1, 423, 103, 4, 168, 24, 2304, 5, 26840, 12, 1, 85, 467, 1378, 29, 27, 4, 19391, 1287, 7, 149, 2964, 9, 124, 3, 2083, 135, 196, 108, 73, 1468, 14, 9181, 39963, 7, 10, 57, 1260, 5, 1223, 183, 40, 1227, 1381, 2, 4962, 204, 76, 3, 855, 17, 5028, 182, 61036, 193, 20, 25, 1, 7441, 5176, 4, 23, 635, 17, 8, 12, 31675, 69, 2275, 2843, 24633, 2, 49, 216, 69, 2642, 3, 78, 212, 5, 137, 63, 14, 330]]\n"
     ]
    }
   ],
   "source": [
    "reviews_int = []\n",
    "for review in reviews_split:\n",
    "    r = [vocab_to_int[w] for w in review.split()]\n",
    "    reviews_int.append(r)\n",
    "print (reviews_int[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive', 'positive', 'positive', 'negative', 'positive']\n"
     ]
    }
   ],
   "source": [
    "labels_split = list(df['sentiment'])\n",
    "print(labels_split[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = [1 if label =='positive' else 0 for label in labels_split]\n",
    "encoded_labels = np.array(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    50000.000000\n",
       "mean       226.236660\n",
       "std        167.608553\n",
       "min          4.000000\n",
       "25%        124.000000\n",
       "50%        170.000000\n",
       "75%        274.000000\n",
       "max       2450.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "reviews_len = [len(x) for x in reviews_int]\n",
    "pd.Series(reviews_len).hist()\n",
    "plt.show()\n",
    "pd.Series(reviews_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_int = [ reviews_int[i] for i, l in enumerate(reviews_len) if l<500 ]\n",
    "encoded_labels = [ encoded_labels[i] for i, l in enumerate(reviews_len) if l< 500 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(reviews_int, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
    "    '''\n",
    "    features = np.zeros((len(reviews_int), seq_length), dtype = int)\n",
    "    \n",
    "    for i, review in enumerate(reviews_int):\n",
    "        review_len = len(review)\n",
    "        \n",
    "        if review_len <= seq_length:\n",
    "            zeroes = list(np.zeros(seq_length-review_len))\n",
    "            new = zeroes+review\n",
    "        elif review_len > seq_length:\n",
    "            new = review[0:seq_length]\n",
    "        \n",
    "        features[i,:] = np.array(new)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46277, 46277)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_int), len(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 0\n",
    "for i in reviews_int:\n",
    "    if len(i) > seq_length: seq_length = len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pad_features(reviews_int, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46277, 499)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frac = 0.8\n",
    "len_feat = features.shape[0]\n",
    "train_x = features[0:int(split_frac*len_feat)]\n",
    "train_y = encoded_labels[0:int(split_frac*len_feat)]\n",
    "remaining_x = features[int(split_frac*len_feat):]\n",
    "remaining_y = encoded_labels[int(split_frac*len_feat):]\n",
    "valid_x = remaining_x[0:int(len(remaining_x)*0.5)]\n",
    "valid_y = remaining_y[0:int(len(remaining_y)*0.5)]\n",
    "test_x = remaining_x[int(len(remaining_x)*0.5):]\n",
    "test_y = remaining_y[int(len(remaining_y)*0.5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(np.array(train_y)))\n",
    "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(np.array(valid_y)))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(np.array(test_y)))\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 499])\n",
      "Sample input: \n",
      " tensor([[   0,    0,    0,  ...,    3,   48,   18],\n",
      "        [   0,    0,    0,  ...,   19, 1762, 1594],\n",
      "        [   0,    0,    0,  ..., 2274,   19, 1011],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ...,  751,  751,  751],\n",
      "        [   0,    0,    0,  ...,    4,   28,  535],\n",
      "        [   0,    0,    0,  ...,   18,   13,   72]], dtype=torch.int32)\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentLSTM(\n",
      "  (embedding): Embedding(222702, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-6e791374afda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# calculate the loss and perform backprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;31m# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gans\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gans\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# training params\n",
    "\n",
    "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "train_on_gpu = False\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        inputs = inputs.type(torch.LongTensor)\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                inputs = inputs.type(torch.LongTensor)\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
