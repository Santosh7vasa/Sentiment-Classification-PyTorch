{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "df = pd.read_csv(\"./data/IMDB Dataset.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    text = re.sub(cleanr, ' ', text)\n",
    "    text = text.lower()\n",
    "    text = regex.sub(' ', text)\n",
    "    text = ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', text)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "    return text\n",
    "def word_process(text, stopwords = False):\n",
    "    text = text.split(\" \")\n",
    "    if stopwords : text = [word for word in text if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "def encoding(text):\n",
    "    text = text.split(\" \")\n",
    "    text = [word2index[word] for word in text]\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production    the filming t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production    the filming t...  positive"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df.copy()\n",
    "text['review'] = df['review'].apply(preprocess)\n",
    "text.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100030\n"
     ]
    }
   ],
   "source": [
    "all_words = word_process(\" \".join(list(text['review'])))\n",
    "words = list(set(all_words))\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "index2word = {}\n",
    "for i,word in enumerate(words):\n",
    "    index2word[i] = word\n",
    "    word2index[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30482,\n",
       " 7466,\n",
       " 67263,\n",
       " 8532,\n",
       " 0,\n",
       " 93487,\n",
       " 42939,\n",
       " 69621,\n",
       " 0,\n",
       " 85329,\n",
       " 0,\n",
       " 72411,\n",
       " 55666,\n",
       " 0,\n",
       " 0,\n",
       " 94012,\n",
       " 74387,\n",
       " 10869,\n",
       " 93487,\n",
       " 91285,\n",
       " 36907,\n",
       " 61570,\n",
       " 29167,\n",
       " 0,\n",
       " 64685,\n",
       " 85329,\n",
       " 19231,\n",
       " 34575,\n",
       " 0,\n",
       " 27740,\n",
       " 0,\n",
       " 96170,\n",
       " 45917,\n",
       " 92200,\n",
       " 23292,\n",
       " 0,\n",
       " 96170,\n",
       " 26675,\n",
       " 85395,\n",
       " 68598,\n",
       " 78449,\n",
       " 0,\n",
       " 87408,\n",
       " 29167,\n",
       " 0,\n",
       " 91181,\n",
       " 0,\n",
       " 48839,\n",
       " 54272,\n",
       " 19231,\n",
       " 0,\n",
       " 0,\n",
       " 47900,\n",
       " 93487,\n",
       " 49320,\n",
       " 20035,\n",
       " 95388,\n",
       " 71730,\n",
       " 65258,\n",
       " 92398,\n",
       " 69748,\n",
       " 0,\n",
       " 32613,\n",
       " 7330,\n",
       " 66830,\n",
       " 30510,\n",
       " 0,\n",
       " 25182,\n",
       " 93144,\n",
       " 30317,\n",
       " 47186,\n",
       " 56725,\n",
       " 17848,\n",
       " 12636,\n",
       " 78327,\n",
       " 0,\n",
       " 11595,\n",
       " 56471,\n",
       " 6277,\n",
       " 0,\n",
       " 81356,\n",
       " 30510,\n",
       " 39839,\n",
       " 58703,\n",
       " 0,\n",
       " 6564,\n",
       " 0,\n",
       " 29084,\n",
       " 0,\n",
       " 69313,\n",
       " 0,\n",
       " 35011,\n",
       " 0,\n",
       " 4203,\n",
       " 0,\n",
       " 92669,\n",
       " 0,\n",
       " 83956,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4530,\n",
       " 0,\n",
       " 60911,\n",
       " 28920,\n",
       " 0,\n",
       " 63592,\n",
       " 63210,\n",
       " 767,\n",
       " 76942,\n",
       " 26773,\n",
       " 55357,\n",
       " 73584,\n",
       " 0,\n",
       " 0,\n",
       " 32471,\n",
       " 24801,\n",
       " 93736,\n",
       " 47918,\n",
       " 96170,\n",
       " 84710,\n",
       " 74184,\n",
       " 16191,\n",
       " 71512,\n",
       " 65165,\n",
       " 0,\n",
       " 76320,\n",
       " 30620,\n",
       " 39277,\n",
       " 90879,\n",
       " 74620,\n",
       " 94064,\n",
       " 0,\n",
       " 76320,\n",
       " 62709,\n",
       " 0,\n",
       " 76320,\n",
       " 1870,\n",
       " 0,\n",
       " 0,\n",
       " 93487,\n",
       " 58876,\n",
       " 46156,\n",
       " 0,\n",
       " 94012,\n",
       " 42939,\n",
       " 7819,\n",
       " 94490,\n",
       " 10869,\n",
       " 58757,\n",
       " 6099,\n",
       " 0,\n",
       " 24801,\n",
       " 31449,\n",
       " 0,\n",
       " 16032,\n",
       " 0,\n",
       " 23713,\n",
       " 5914,\n",
       " 93487,\n",
       " 0,\n",
       " 34059,\n",
       " 13707,\n",
       " 56471,\n",
       " 50211,\n",
       " 1930,\n",
       " 29167,\n",
       " 0,\n",
       " 29167,\n",
       " 0,\n",
       " 42336,\n",
       " 0,\n",
       " 94011,\n",
       " 30996,\n",
       " 95125,\n",
       " 29803,\n",
       " 0,\n",
       " 37956,\n",
       " 6470,\n",
       " 97433,\n",
       " 92589,\n",
       " 73584,\n",
       " 0,\n",
       " 17764,\n",
       " 59226,\n",
       " 0,\n",
       " 97972,\n",
       " 65978,\n",
       " 37956,\n",
       " 50283,\n",
       " 30317,\n",
       " 54573,\n",
       " 84710,\n",
       " 44674,\n",
       " 62799,\n",
       " 27965,\n",
       " 30317,\n",
       " 960,\n",
       " 0,\n",
       " 8532,\n",
       " 93487,\n",
       " 0,\n",
       " 59789,\n",
       " 27622,\n",
       " 95194,\n",
       " 54105,\n",
       " 18633,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 54643,\n",
       " 92589,\n",
       " 95178,\n",
       " 38145,\n",
       " 33065,\n",
       " 0]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding(\" \".join(word_process(preprocess(df['review'][0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_words = Counter(all_words)\n",
    "total_words = len(words)\n",
    "sorted_words = count_words.most_common(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_int = {w:i for i, (w,c) in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(text['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28, 4, 1, 77, 2038, 46, 1050, 11, 100, 149, 41, 3061, 394, 20, 230, 29, 3174, 32, 25, 203, 14, 10, 6, 613, 47, 592, 17, 68, 1, 87, 148, 11, 3217, 68, 44, 3061, 13, 90, 5322, 2, 14820, 135, 4, 559, 61, 265, 8, 203, 37, 1, 647, 141, 1722, 68, 10, 6, 23, 3, 116, 16, 1, 7810, 2312, 40, 11302, 10, 116, 2571, 56, 5848, 17, 5442, 5, 1452, 371, 40, 559, 90, 6, 3784, 8, 1, 355, 356, 4, 1, 647, 7, 6, 433, 3061, 14, 11, 6, 1, 11473, 357, 5, 1, 14535, 6752, 2517, 1031, 50211, 7, 2684, 1399, 22, 22659, 518, 34, 4620, 2439, 4, 1, 1180, 115, 30, 1, 6931, 27, 2881, 11786, 2, 385, 50212, 36, 16327, 6, 23, 297, 22, 1, 4836, 2907, 518, 6, 340, 5, 107, 24380, 8063, 39249, 14536, 4993, 7691, 2426, 2, 52, 36, 43676, 324, 8981, 7236, 12281, 2, 8579, 31241, 25, 112, 223, 240, 9, 60, 132, 1, 280, 1315, 4, 1, 116, 6, 680, 5, 1, 192, 11, 7, 266, 115, 77, 274, 572, 21, 2982, 816, 182, 1287, 4124, 16, 2475, 1213, 816, 1418, 816, 863, 3061, 152, 21, 938, 184, 1, 87, 394, 9, 123, 209, 3217, 68, 14, 36, 1603, 7, 13, 2216, 9, 411, 21, 132, 9, 13, 1569, 16, 7, 18, 14, 9, 290, 52, 9, 1402, 3, 1253, 16, 3061, 2, 190, 10035, 5, 1, 297, 2020, 4, 2120, 559, 23, 41, 559, 18, 7574, 7080, 4961, 35, 230, 29, 2957, 43, 16, 3, 22660, 6796, 35, 230, 494, 22, 627, 2, 75, 240, 17, 7, 70, 7516, 639, 694, 6796, 109, 648, 83, 1180, 18826, 680, 5, 66, 564, 4, 890, 2000, 40, 1180, 549, 149, 3061, 20, 197, 426, 3801, 17, 47, 6, 3285, 795, 1516, 45, 20, 50, 75, 8, 1197, 17, 126, 4058, 479], [3, 389, 120, 350, 1, 1364, 2950, 6, 53, 17438, 53, 158, 57, 2144, 1566, 2, 409, 3, 13069, 2, 525, 25399, 281, 4, 1816, 5, 1, 439, 410, 1, 150, 25, 557, 70, 2251, 481, 4125, 23, 62, 46, 190, 30, 1, 62088, 18, 24, 46, 30, 1, 2267, 176, 3249, 97, 20, 50, 367, 65, 1, 13070, 777, 9581, 33, 1, 1814, 5, 1713, 7237, 6514, 23, 62, 6, 7, 70, 276, 1, 149, 18, 7, 6, 3, 35993, 404, 2, 2377, 410, 3, 4291, 350, 44, 28, 4, 1, 80, 1127, 12, 4, 200, 2, 26, 113, 1, 1816, 64, 270, 340, 17, 1, 120, 179, 1, 1005, 4, 1, 2862, 61, 248, 72, 356, 1, 2179, 952, 3100, 1268, 1173, 93, 4876, 7, 298, 22, 256, 1813, 2, 256, 4513, 574, 17, 1, 135, 3666, 18330, 2, 24381, 2, 1, 717, 574, 4, 66, 1034, 17, 24381, 12, 43677, 26584, 171, 2271, 25, 1951, 70, 219], [9, 191, 10, 13, 3, 389, 95, 5, 1138, 57, 22, 3, 97, 854, 1450, 2572, 1222, 8, 1, 883, 14537, 756, 2, 149, 3, 633, 2312, 200, 1, 111, 6, 4059, 18, 1, 408, 6, 1890, 2, 1, 101, 25, 1465, 59, 1, 70, 6010, 6604, 1540, 470, 136, 48, 197, 29, 667, 51, 32, 945, 10, 6, 23, 1006, 217, 2893, 5102, 9, 191, 7, 13, 3018, 11, 2812, 1767, 6, 131, 1385, 8, 1115, 4, 1, 393, 107, 4, 178, 27, 2039, 5, 110, 10, 13, 1, 89, 9, 222, 1424, 31, 28, 4, 2812, 12, 1291, 8, 154, 2982, 9, 132, 3, 2040, 136, 9, 137, 112, 76, 1489, 17, 8126, 29444, 8, 10, 54, 1312, 5, 1238, 176, 42, 1230, 1404, 2, 5035, 203, 83, 3, 830, 18, 3514, 186, 245, 10, 197, 23, 29, 1, 7131, 5056, 4, 26, 614, 18, 7, 13, 29445, 72, 1799, 2908, 23464, 2, 52, 218, 72, 2490, 3, 80, 200, 5, 141, 65, 17, 348]]\n"
     ]
    }
   ],
   "source": [
    "reviews_encoded = []\n",
    "for review in reviews:\n",
    "    r = [vocab_to_int[w] for w in review.split()]\n",
    "    reviews_encoded.append(r)\n",
    "print (reviews_encoded[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_lens = [len(enc) for enc in reviews_encoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2492"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(review_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234.08298"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(review_lens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(text['sentiment'])\n",
    "encoded_labels = [1 if label =='positive' else 0 for label in labels]\n",
    "encoded_labels = np.array(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_encoded = [ reviews_encoded[i] for i, l in enumerate(review_lens) if l<500 ]\n",
    "encoded_labels = np.array([ encoded_labels[i] for i, l in enumerate(review_lens) if l< 500 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45957, 45957)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_encoded), len(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(reviews_int, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
    "    '''\n",
    "    features = np.zeros((len(reviews_int), seq_length), dtype = int)\n",
    "    \n",
    "    for i, review in enumerate(reviews_int):\n",
    "        review_len = len(review)\n",
    "        \n",
    "        if review_len <= seq_length:\n",
    "            zeroes = list(np.zeros(seq_length-review_len))\n",
    "            new = zeroes+review\n",
    "        elif review_len > seq_length:\n",
    "            new = review[0:seq_length]\n",
    "        \n",
    "        features[i,:] = np.array(new)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pad_features(reviews_encoded, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frac = 0.8\n",
    "len_feat = features.shape[0]\n",
    "train_x = features[0:int(split_frac*len_feat)]\n",
    "train_y = encoded_labels[0:int(split_frac*len_feat)]\n",
    "remaining_x = features[int(split_frac*len_feat):]\n",
    "remaining_y = encoded_labels[int(split_frac*len_feat):]\n",
    "valid_x = remaining_x[0:int(len(remaining_x)*0.5)]\n",
    "valid_y = remaining_y[0:int(len(remaining_y)*0.5)]\n",
    "test_x = remaining_x[int(len(remaining_x)*0.5):]\n",
    "test_y = remaining_y[int(len(remaining_y)*0.5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch Datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "# make sure to SHUFFLE your data\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 500])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,  ...,     1,    49,   160],\n",
      "        [    0,     0,     0,  ...,     7,    43,     4],\n",
      "        [    0,     0,     0,  ...,     4,     1,    15],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,   745,     4, 13258],\n",
      "        [    0,     0,     0,  ...,   206,     1, 17716],\n",
      "        [    0,     0,     0,  ...,     5,    65,   105]], dtype=torch.int32)\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length # batch_size sentences at once\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size # batch_size labels at once\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentLSTM(\n",
      "  (embedding): Embedding(100031, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
